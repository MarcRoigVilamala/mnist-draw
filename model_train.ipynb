{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" --- IMPORTACION LIBRERIAS --- \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pathlib\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## load mnist dataset\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "trans = transforms.ToTensor()\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 600\n",
      "==>>> total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (x, target) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f414cdc23c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "which_sample = 2\n",
    "plt.imshow(samples[which_sample].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## network\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "model = MLPNet()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 100, train loss: 0.256688, test loss: 0.233275, acc: 0.923\n",
      "==>>> epoch: 1, batch index: 100, train loss: 0.225994, test loss: 0.168282, acc: 0.946\n",
      "==>>> epoch: 2, batch index: 100, train loss: 0.135259, test loss: 0.126223, acc: 0.956\n",
      "==>>> epoch: 3, batch index: 100, train loss: 0.112979, test loss: 0.106205, acc: 0.964\n",
      "==>>> epoch: 4, batch index: 100, train loss: 0.087054, test loss: 0.088318, acc: 0.971\n",
      "==>>> epoch: 5, batch index: 100, train loss: 0.081657, test loss: 0.081239, acc: 0.968\n",
      "==>>> epoch: 6, batch index: 100, train loss: 0.062081, test loss: 0.065759, acc: 0.976\n",
      "==>>> epoch: 7, batch index: 100, train loss: 0.042542, test loss: 0.059338, acc: 0.979\n",
      "==>>> epoch: 8, batch index: 100, train loss: 0.055839, test loss: 0.065439, acc: 0.976\n",
      "==>>> epoch: 9, batch index: 100, train loss: 0.041584, test loss: 0.066380, acc: 0.978\n",
      "==>>> epoch: 10, batch index: 100, train loss: 0.036102, test loss: 0.055581, acc: 0.979\n",
      "==>>> epoch: 11, batch index: 100, train loss: 0.032823, test loss: 0.051203, acc: 0.980\n",
      "==>>> epoch: 12, batch index: 100, train loss: 0.024026, test loss: 0.048682, acc: 0.980\n",
      "==>>> epoch: 13, batch index: 100, train loss: 0.028382, test loss: 0.056439, acc: 0.980\n",
      "==>>> epoch: 14, batch index: 100, train loss: 0.025710, test loss: 0.055719, acc: 0.981\n",
      "==>>> epoch: 15, batch index: 100, train loss: 0.013693, test loss: 0.053473, acc: 0.980\n",
      "==>>> epoch: 16, batch index: 100, train loss: 0.011266, test loss: 0.047682, acc: 0.981\n",
      "==>>> epoch: 17, batch index: 100, train loss: 0.010853, test loss: 0.054304, acc: 0.980\n",
      "==>>> epoch: 18, batch index: 100, train loss: 0.009898, test loss: 0.052856, acc: 0.982\n",
      "==>>> epoch: 19, batch index: 100, train loss: 0.009587, test loss: 0.049229, acc: 0.980\n",
      "==>>> epoch: 20, batch index: 100, train loss: 0.006124, test loss: 0.050367, acc: 0.981\n",
      "==>>> epoch: 21, batch index: 100, train loss: 0.005586, test loss: 0.055162, acc: 0.980\n",
      "==>>> epoch: 22, batch index: 100, train loss: 0.006876, test loss: 0.051844, acc: 0.982\n",
      "==>>> epoch: 23, batch index: 100, train loss: 0.004771, test loss: 0.049021, acc: 0.982\n",
      "==>>> epoch: 24, batch index: 100, train loss: 0.006137, test loss: 0.050647, acc: 0.981\n",
      "==>>> epoch: 25, batch index: 100, train loss: 0.003871, test loss: 0.053313, acc: 0.981\n",
      "==>>> epoch: 26, batch index: 100, train loss: 0.004270, test loss: 0.054676, acc: 0.981\n",
      "==>>> epoch: 27, batch index: 100, train loss: 0.002482, test loss: 0.055669, acc: 0.982\n",
      "==>>> epoch: 28, batch index: 100, train loss: 0.002034, test loss: 0.055008, acc: 0.981\n",
      "==>>> epoch: 29, batch index: 100, train loss: 0.002058, test loss: 0.055788, acc: 0.981\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    # trainning\n",
    "    ave_loss_train = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        ave_loss_train = ave_loss_train * 0.9 + loss.item() * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # testing\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "        \n",
    "        # smooth average\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "        \n",
    "        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.6f}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx+1, ave_loss_train, ave_loss, correct_cnt.item() * 1.0 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/mlp_mnist.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
